{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning Agent\n",
    "\n",
    "Hilfreiche Erklärungen am Beispiel CartPole:\n",
    "- https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "- https://www.tensorflow.org/agents/tutorials/1_dqn_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abhängigkeiten installieren\n",
    "\n",
    "Achtung: tf-agents 0.19.0 benötigt typing-extensions==4.5.0, ipython jedoch Version 4.6.0. Daher kann es zu Fehlermeldungen beim `Neustarten` kommen.  \n",
    "`Alles Ausführen` funktioniert dennoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython==8.23.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (8.23.0)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.10/site-packages (from ipython==8.23.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/codespace/.local/lib/python3.10/site-packages (from ipython==8.23.0) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/codespace/.local/lib/python3.10/site-packages (from ipython==8.23.0) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/codespace/.local/lib/python3.10/site-packages (from ipython==8.23.0) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from ipython==8.23.0) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/codespace/.local/lib/python3.10/site-packages (from ipython==8.23.0) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from ipython==8.23.0) (5.14.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/codespace/.local/lib/python3.10/site-packages (from ipython==8.23.0) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/python/3.10.13/lib/python3.10/site-packages (from ipython==8.23.0) (4.5.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/codespace/.local/lib/python3.10/site-packages (from ipython==8.23.0) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/codespace/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython==8.23.0) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/codespace/.local/lib/python3.10/site-packages (from pexpect>4.3->ipython==8.23.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython==8.23.0) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from stack-data->ipython==8.23.0) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from stack-data->ipython==8.23.0) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/codespace/.local/lib/python3.10/site-packages (from stack-data->ipython==8.23.0) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython==8.23.0) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tf_keras==2.15.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tf-agents==0.19.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents[reverb]==0.19.0) (0.19.0)\n",
      "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (2.1.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (3.0.0)\n",
      "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (0.5.0)\n",
      "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (1.26.4)\n",
      "Requirement already satisfied: pillow in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (10.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/codespace/.local/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (4.25.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (4.5.0)\n",
      "Requirement already satisfied: pygame==2.1.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (2.1.3)\n",
      "Requirement already satisfied: tensorflow-probability~=0.23.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (0.23.0)\n",
      "Requirement already satisfied: rlds in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents[reverb]==0.19.0) (0.1.8)\n",
      "Requirement already satisfied: dm-reverb~=0.14.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents[reverb]==0.19.0) (0.14.0)\n",
      "Requirement already satisfied: tensorflow~=2.15.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tf-agents[reverb]==0.19.0) (2.15.1)\n",
      "Requirement already satisfied: dm-tree in /usr/local/python/3.10.13/lib/python3.10/site-packages (from dm-reverb~=0.14.0->tf-agents[reverb]==0.19.0) (0.1.8)\n",
      "Requirement already satisfied: portpicker in /usr/local/python/3.10.13/lib/python3.10/site-packages (from dm-reverb~=0.14.0->tf-agents[reverb]==0.19.0) (1.6.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from gym<=0.23.0,>=0.17.0->tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (0.0.8)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (24.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (68.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (2.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (0.37.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (2.15.0)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow-probability~=0.23.0->tf-agents==0.19.0->tf-agents[reverb]==0.19.0) (5.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (2.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (3.0.3)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.10/site-packages (from portpicker->dm-reverb~=0.14.0->tf-agents[reverb]==0.19.0) (6.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]==0.19.0) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /usr/local/python/3.10.13/lib/python3.10/site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tf_keras==2.15.0\n",
    "%pip install tf-agents[reverb]==0.19.0\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Keep using keras-2 (tf-keras) rather than keras-3 (keras).\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reverb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tf_agents import trajectories as ts\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.policies import boltzmann_policy\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.policies import epsilon_greedy_policy\n",
    "from tf_agents.policies import q_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.drivers import py_driver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umgebung definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoginEnv(py_environment.PyEnvironment):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Zustandseigenschaften: Richtiges Passwort (boolean), Zeit zwischen Loginversuchen (date), Falsches Passwort Zähler (int), letzte Aktion (int)\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "                                shape=(4,), dtype=np.int32, minimum=0, name='observation')\n",
    "        \n",
    "        # Aktionen: 0 = Nicht sperren, 1 = 30s sperren, 2 = 1m sperren, 3 = 3min sperren, 4 = Dauerhaft sperren\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "                                shape=(), dtype=np.int32, minimum=0, maximum=4, name='action')\n",
    "        \n",
    "        # Interne Zustandsvariablen initialisieren\n",
    "        self._state = np.array([0, 0, 0, 0], dtype=np.int32)\n",
    "        self._episode_ended = False\n",
    "    \n",
    "    def _reset(self):\n",
    "        self._state[0] = np.random.choice([0, 1])  # Richtiges Passwort: 0 oder 1\n",
    "        self._state[1] = np.random.randint(0, 3600)  # Zeit zwischen Loginversuchen\n",
    "        self._state[2] = np.random.randint(0, 11)  # Falsches Passwort Zähler\n",
    "        self._state[3] = np.random.randint(1, 3) if self._state[2] > 0 else 0  # Letzte Aktion\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array(self._state, dtype=np.int32))\n",
    "\n",
    "    def _step(self, action):\n",
    "        if self._episode_ended:\n",
    "            return self.reset()\n",
    "        \n",
    "        reward = 0\n",
    "        if action == 0:  # Nicht sperren\n",
    "            if self._state[0] == 0:\n",
    "                reward = 1\n",
    "                self._episode_ended = True\n",
    "            elif self._state[1] <= 3 or self._state[2] >= 10:\n",
    "                reward = -1\n",
    "                self._episode_ended = True\n",
    "        else:\n",
    "            reward = 1\n",
    "            self._episode_ended = True\n",
    "            \n",
    "        \"\"\" elif action == 1:  # 30s sperren\n",
    "            if self._state[0] == 0:\n",
    "                reward = -1\n",
    "                self._episode_ended = True\n",
    "            elif self._state[1] <= 3 or (3 < self._state[2] <= 6):\n",
    "                reward = 1\n",
    "                self._episode_ended = True\n",
    "        elif action == 2:  # 1m sperren\n",
    "            if self._state[0] == 0:\n",
    "                reward = -1\n",
    "                self._episode_ended = True\n",
    "            elif 6 < self._state[2] <= 9:\n",
    "                reward = 1\n",
    "                self._episode_ended = True\n",
    "        elif action == 3:  # 3min sperren\n",
    "            if self._state[0] == 0:\n",
    "                reward = -1\n",
    "                self._episode_ended = True\n",
    "            elif 9 < self._state[2] < 10:\n",
    "                reward = 1\n",
    "                self._episode_ended = True\n",
    "        elif action == 4:  # Dauerhaft sperren\n",
    "            if self._state[2] >= 10:\n",
    "                reward = 1\n",
    "                self._episode_ended = True\n",
    "            else:\n",
    "                reward = -1\n",
    "                self._episode_ended = True \"\"\"\n",
    "    \n",
    "        if self._episode_ended:\n",
    "            return ts.termination(np.array(self._state, dtype=np.int32), reward)\n",
    "        else:\n",
    "            return ts.transition(np.array(self._state, dtype=np.int32), reward=0.0, discount=1.0)\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_env = LoginEnv()\n",
    "train_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(py_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Reinforcement Learning Agent (DQN-Agent) definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle das Q-Network\n",
    "fc_layer_params = (100,)\n",
    "q_net = q_network.QNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n",
    "\n",
    "# Konfiguriere den DQN-Agenten\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "train_step_counter = tf.Variable(0)\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "# Initialisiere und kompiliere den Agenten\n",
    "agent.initialize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy = boltzmann_policy.BoltzmannPolicy(agent.policy)\n",
    "#policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(), train_env.action_spec())\n",
    "policy = epsilon_greedy_policy.EpsilonGreedyPolicy(agent.policy, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metriken und Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_return(environment, policy, num_episodes=10):\n",
    "    print(f\"Starte Berechnung der durchschnittlichen Rückkehr über {num_episodes} Episoden.\")\n",
    "    total_return = 0.0\n",
    "    for episode in range(num_episodes):\n",
    "        print(f\"Episode {episode+1}/{num_episodes} startet.\")\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "        step_count = 0\n",
    "        while not time_step.is_last():\n",
    "            step_count += 1\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "            print(f\"  Schritt {step_count}, Zwischensumme der Rückkehr: {episode_return}\")\n",
    "        total_return += episode_return\n",
    "        print(f\"Episode {episode+1} abgeschlossen. Rückkehr: {episode_return}\")\n",
    "    average_return = total_return / num_episodes\n",
    "    print(f\"Durchschnittliche Rückkehr nach {num_episodes} Episoden: {average_return}\")\n",
    "    return average_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiederholungspuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/tfrecord_checkpointer.cc:162]  Initializing TFRecordCheckpointer in /tmp/tmpudh_x7yy.\n",
      "[reverb/cc/platform/tfrecord_checkpointer.cc:565] Loading latest checkpoint from /tmp/tmpudh_x7yy\n",
      "[reverb/cc/platform/default/server.cc:71] Started replay server on port 42887\n"
     ]
    }
   ],
   "source": [
    "# Create a replay buffer table\n",
    "table_name = 'replay_buffer'\n",
    "replay_buffer_signature = tensor_spec.from_spec(\n",
    "    agent.collect_data_spec)\n",
    "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "    replay_buffer_signature)\n",
    "\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=100000,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "    signature=replay_buffer_signature)\n",
    "\n",
    "# Create a replay buffer server\n",
    "reverb_server = reverb.Server([table])\n",
    "\n",
    "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    local_server=reverb_server)\n",
    "\n",
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "    replay_buffer.py_client,\n",
    "    table_name,\n",
    "    sequence_length=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensammlung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7ab85ecd7bb0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/default/server.cc:84] Shutting down replay server\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=64,\n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training des Agenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized training.\n",
      "reseted\n",
      "Starte Berechnung der durchschnittlichen Rückkehr über 10 Episoden.\n",
      "Episode 1/10 startet.\n",
      "  Schritt 1, Zwischensumme der Rückkehr: [1.]\n",
      "Episode 1 abgeschlossen. Rückkehr: [1.]\n",
      "Episode 2/10 startet.\n",
      "  Schritt 1, Zwischensumme der Rückkehr: [1.]\n",
      "Episode 2 abgeschlossen. Rückkehr: [1.]\n",
      "Episode 3/10 startet.\n",
      "  Schritt 1, Zwischensumme der Rückkehr: [1.]\n",
      "Episode 3 abgeschlossen. Rückkehr: [1.]\n",
      "Episode 4/10 startet.\n",
      "  Schritt 1, Zwischensumme der Rückkehr: [1.]\n",
      "Episode 4 abgeschlossen. Rückkehr: [1.]\n",
      "Episode 5/10 startet.\n",
      "  Schritt 1, Zwischensumme der Rückkehr: [1.]\n",
      "Episode 5 abgeschlossen. Rückkehr: [1.]\n",
      "Episode 6/10 startet.\n",
      "  Schritt 1, Zwischensumme der Rückkehr: [1.]\n",
      "Episode 6 abgeschlossen. Rückkehr: [1.]\n",
      "Episode 7/10 startet.\n",
      "  Schritt 1, Zwischensumme der Rückkehr: [1.]\n",
      "Episode 7 abgeschlossen. Rückkehr: [1.]\n",
      "Episode 8/10 startet.\n",
      "  Schritt 1, Zwischensumme der Rückkehr: [1.]\n",
      "Episode 8 abgeschlossen. Rückkehr: [1.]\n",
      "Episode 9/10 startet.\n",
      "  Schritt 1, Zwischensumme der Rückkehr: [1.]\n",
      "Episode 9 abgeschlossen. Rückkehr: [1.]\n",
      "Episode 10/10 startet.\n",
      "  Schritt 1, Zwischensumme der Rückkehr: [1.]\n",
      "Episode 10 abgeschlossen. Rückkehr: [1.]\n",
      "Durchschnittliche Rückkehr nach 10 Episoden: [1.]\n",
      "evaluated\n",
      "reseted\n",
      "Erfahrung sammeln...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (15677) so Table replay_buffer is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (15677) so Table replay_buffer is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (15677) so Table replay_buffer is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (15677) so Table replay_buffer is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (15677) so Table replay_buffer is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (15677) so Table replay_buffer is accessed directly without gRPC.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "print(\"Optimized training.\")\n",
    "\n",
    "# Reset the train step.\n",
    "agent.train_step_counter.assign(0)\n",
    "print(\"reseted\")\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_average_return(eval_env, agent.policy, 10)\n",
    "returns = [avg_return]\n",
    "print(\"evaluated\")\n",
    "      \n",
    "# Reset the environment.\n",
    "time_step = train_env.reset()\n",
    "print(\"reseted\")\n",
    "\n",
    "# Create a driver to collect experience.\n",
    "collect_driver = py_driver.PyDriver(\n",
    "    train_env, #CHANGE\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      agent.collect_policy, \n",
    "      use_tf_function=True, \n",
    "      batch_time_steps=False #CHANGE\n",
    "      ),\n",
    "    [rb_observer],\n",
    "    max_steps=1)\n",
    "\n",
    "import time\n",
    "\n",
    "for _ in range(20):\n",
    "  print(\"Erfahrung sammeln...\")\n",
    "  start_time = time.time()  # Startzeit für das Sammeln der Erfahrung\n",
    "  experience, unused_info = next(iterator)\n",
    "  duration = time.time() - start_time  # Dauer des Sammelns\n",
    "  print(f\"Erfahrung gesammelt in {duration:.2f} Sekunden\")\n",
    "\n",
    "  # Überprüfen der Größe der gesammelten Erfahrung\n",
    "  num_experiences = len(experience)\n",
    "  print(f\"Anzahl der gesammelten Erfahrungen: {num_experiences}\")\n",
    "\n",
    "  print(\"Aktualisiere Netzwerk...\")\n",
    "  train_loss = agent.train(experience).loss\n",
    "  print(f\"Trainingsverlust: {train_loss}\")\n",
    "\n",
    "  \"\"\"   print(\"collect\")\n",
    "    # Collect a few steps and save to the replay buffer.\n",
    "    time_step, _ = collect_driver.run(time_step)\n",
    "    print(\"sample a batch\")\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience).loss\n",
    "  \"\"\"\n",
    "  print(\"step\")\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % 200 == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % 1000 == 0:\n",
    "    avg_return = compute_average_return(eval_env, agent.policy, 10)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel konnte nicht gestartet werden, da „TypeAliasType“ nicht von „/home/codespace/.python/current/lib/python3.10/site-packages/typing_extensions.py“ importiert werden konnte.\n",
      "\u001b[1;31mKlicken Sie <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>hier</a>, um weitere Informationen zu erhalten."
     ]
    }
   ],
   "source": [
    "# funktioniert nicht, da 4 Dimensionen\n",
    "iterations = range(0, 20000 + 1, 1000)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
